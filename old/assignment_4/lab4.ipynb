{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "30acc64281909950442f23bac1c57f94",
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Problem Set 4: Visualization, $k$-Means/E-M, Spectral Clustering\n",
    "\n",
    "We're back to using `scikit-learn` now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "0fc5625c1804a1fc86881b56a7a80f56",
     "grade": false,
     "grade_id": "boilerplate",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Boilerplate\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils.extmath import row_norms\n",
    "# Some scaling functions\n",
    "from sklearn.preprocessing import robust_scale, minmax_scale, maxabs_scale, scale\n",
    "# Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GMM\n",
    "# Iris dataset\n",
    "from sklearn.datasets import load_iris\n",
    "# Random datasets\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "# For visualization\n",
    "from sklearn.manifold import TSNE, MDS, SpectralEmbedding, spectral_embedding\n",
    "from sklearn.decomposition import PCA\n",
    "# Distances and kernels\n",
    "from sklearn.metrics.pairwise import cosine_distances, manhattan_distances, rbf_kernel, laplacian_kernel, euclidean_distances\n",
    "    \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Magic function to make matplotlib inline; other style specs must come AFTER\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable high resolution PNGs\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "# Seaborn settings for notebooks\n",
    "rc = {'lines.linewidth': 2, \n",
    "      'axes.labelsize': 18, \n",
    "      'axes.titlesize': 18, \n",
    "      'axes.facecolor': '#DFDFE5'}\n",
    "sns.set(context='notebook', style='darkgrid', rc=rc)\n",
    "\n",
    "# Our familiar plot_clusters function:\n",
    "# hue: the labels we want to use, should be a column name of df\n",
    "# vars: the dimensions that we want to plot, should be a list of \n",
    "#       column names from df\n",
    "def plot_clusters(df, hue='ypred', vars=None): \n",
    "    # Plot the cluster labels:\n",
    "    g = sns.pairplot(data=df, hue=hue, palette='Dark2', vars=vars)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def plot_clusters2d(df, hue='ypred', vars=['T0','T1']):\n",
    "    # Plot the cluster labels:\n",
    "    g = sns.FacetGrid(data=df, size=5, hue=hue, palette='Dark2', subplot_kws=dict(aspect='equal'))\n",
    "    g.map(plt.scatter, vars[0], vars[1], edgecolor=\"w\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6d684a30cc4af456be81f0f4551661db",
     "grade": false,
     "grade_id": "sec-1-desc",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Section 1: Visualization\n",
    "\n",
    "We'll use the Iris data since we're already familiar with that set from a couple assignments ago. Let's load it the same way into `df_iris` the same way as in PS2 and then plot with the real labels (`real_labels`) from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "311de81ed64c7f7b2ec2a24648b08ea4",
     "grade": false,
     "grade_id": "sec-1-code-1",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# First, load the iris data\n",
    "iris = load_iris()\n",
    "\n",
    "# The data is in list format, so make it into an array:\n",
    "X_iris = np.array(iris.data)\n",
    "iris_samples, iris_features = X_iris.shape\n",
    "\n",
    "# It will be convenient later to randomize the order, \n",
    "# but it's less confusing to do it here\n",
    "order = check_random_state(201610270).permutation(iris_samples)\n",
    "X_iris = X_iris[order]\n",
    "\n",
    "# Give the columns of the DataFrame the names of the features\n",
    "df_iris = pd.DataFrame(X_iris, columns=iris['feature_names'])\n",
    "\n",
    "# Add the actual labels from the dataset into the DataFrame \n",
    "# for comparison\n",
    "df_iris['real_labels'] = np.array(iris['target'])[order]\n",
    "\n",
    "plot_clusters(df_iris, hue='real_labels', vars=['sepal length (cm)','sepal width (cm)', 'petal length (cm)', 'petal width (cm)'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f4286b1fdc3bff671ddf088e0ded2430",
     "grade": false,
     "grade_id": "pca-desc",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Problem 1 (PCA)\n",
    "\n",
    "First we're going to mess around with some visualizations. In the first problem, we're going to build a PCA visualization by coding it, and use it to take a look at the iris dataset.\n",
    "\n",
    "Fill in the following function's missing pieces to get it to produce PCA components as discussed in class (the test will see if the function returns reasonably-close values and will also produce a visualization using `plot_clusters`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "051f8e90dd475eb223c3389c424cf58d",
     "grade": false,
     "grade_id": "pca-ans",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def pca_components(X):\n",
    "    \n",
    "    # Find the mean of all of the examples in X, if X has \n",
    "    # shape (n_examples, n_features). The shape of mean_X\n",
    "    # should either be (n_features,) or (1, n_features).\n",
    "    # Remember: there is an easy way to do this!\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Take the SVD. The shapes of the variables are:\n",
    "    # U    : (n_examples, n_features)\n",
    "    # Sigma: (n_features,)\n",
    "    # V    : (n_features, n_features)\n",
    "    #\n",
    "    # In this version of the SVD, the following matrix equation is true:\n",
    "    # X = U * Sigma * V\n",
    "    # (within a certain amount of tolerance)\n",
    "    U, Sigma, V = np.linalg.svd(X-mean_X, full_matrices=False)\n",
    "\n",
    "    # Construct a variable C of shape (n_examples, n_features) that \n",
    "    # contains the components of the PCA:\n",
    "    #\n",
    "    # Sigma is a diagonal matrix, so it only needs to be represented\n",
    "    # by a vector. To make it a diagonal matrix, use np.diag(Sigma).\n",
    "    # (But technically you don't need to do this.)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "05cb0c2ab95c60574b393690e00170e2",
     "grade": true,
     "grade_id": "pca-test",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "C = pca_components(X_iris)\n",
    "\n",
    "df_iris['C0'] = C[:,0]\n",
    "df_iris['C1'] = C[:,1]\n",
    "plot_clusters2d(df_iris, hue='real_labels', vars=['C0','C1'])\n",
    "\n",
    "# Compare with what sklearn.decomposition.PCA gives us\n",
    "assert(np.isclose(C, PCA().fit_transform(X_iris)).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4a3fb1aa113169fdc5ba38ff26d2b45d",
     "grade": false,
     "grade_id": "mds-desc-1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "PCA gives us a fairly nice-looking visualization that separates the real labels of the dataset pretty well. Recall also that we didn't feed the real labels into the visualization -- the labels are already nicely separated within the data. \n",
    "\n",
    "## Problem 2 (MDS)\n",
    "\n",
    "### Part 1:\n",
    "Now let's try with MDS, using the default parameters, and an arbitrary random seed. Let's start out with euclidean distance and then change the metric to try for something better. The `n_init` tells us how many attempts at the best embedding we'll try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "c66df02af285d5b587cd4996b3066ffe",
     "grade": false,
     "grade_id": "mds-code-1",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "mds = MDS(random_state=201610270, n_init=50, dissimilarity='precomputed')\n",
    "M = mds.fit_transform(euclidean_distances(X_iris))\n",
    "df_iris['M0'] = M[:,0]\n",
    "df_iris['M1'] = M[:,1]\n",
    "plot_clusters2d(df_iris, hue='real_labels', vars=['M0','M1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "28829d18e381fe9c82634af60d7e1f77",
     "grade": false,
     "grade_id": "mds-desc-2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This doesn't do any better than PCA, and in fact produces a nearly identical embedding (why? not graded, just think about it).\n",
    "\n",
    "Let's try with other metrics, do inject some nonlinearity into the mix. Try some of them out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "24e3767b111002212c4a378ccdb3835c",
     "grade": false,
     "grade_id": "mds-ans-1",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def other_metrics(X, metric=None):\n",
    "    if metric is None:\n",
    "        raise ValueError('You need to pick something')\n",
    "        \n",
    "    if metric == 'euclidean_distances':\n",
    "        return euclidean_distances(X)\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(X)\n",
    "    if metric == 'manhattan':\n",
    "        return manhattan_distances(X)\n",
    "    if metric == 'laplacian':\n",
    "        return 1-laplacian_kernel(X)\n",
    "    if metric == 'gaussian':\n",
    "        return 1-rbf_kernel(X)\n",
    "\n",
    "# Set `metric` to be one of 'cosine', 'manhattan', 'laplacian', or 'gaussian':\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7259c2bdaf90f0ba3d5adedd19a6b4b0",
     "grade": true,
     "grade_id": "mds-test-1",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# We can just recycle the `mds` object from above\n",
    "M = mds.fit_transform(other_metrics(X_iris, metric=metric))\n",
    "df_iris['M0'] = M[:,0]\n",
    "df_iris['M1'] = M[:,1]\n",
    "plot_clusters2d(df_iris, hue='real_labels', vars=['M0','M1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d3580e6ba135dad23a8189520fe3582f",
     "grade": false,
     "grade_id": "mds-desc-3",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Part 2:\n",
    "Which is the best for visualizing the structure of the data? Expand on your opinion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bf269fa015170b7ffd07eaf70b7dae94",
     "grade": true,
     "grade_id": "mds-ans-2",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d503abdbd5abd20f54f11c9fb0d4b2b7",
     "grade": false,
     "grade_id": "tsne-desc-1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Problem 3 (t-SNE)\n",
    "\n",
    "### Part 1:\n",
    "Now let's try with t-SNE, using the default parameters, and an arbitrary random seed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "3a270d4a89147f45743c98ca807a0db0",
     "grade": false,
     "grade_id": "tsne-code",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "tsne_params = dict(random_state=201610278, n_components=2)\n",
    "tsne = TSNE(**tsne_params)\n",
    "T = tsne.fit_transform(X_iris)\n",
    "df_iris['T0'] = T[:,0]\n",
    "df_iris['T1'] = T[:,1]\n",
    "plot_clusters2d(df_iris, hue='real_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "105d46ba7c22e2e337c8ae0d18ab5d7e",
     "grade": false,
     "grade_id": "tsne-desc-2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This...well, this sucks. I thought that t-SNE was supposed to produce these awesome embeddings! Try to play with the parameters to get something better (this is one of the problems with t-SNE that balances its advantages).\n",
    "\n",
    "You're welcome to do this by hand or automate the process. Just make sure that you change `tsne_params` and that it is still a `dict` object, using [the descriptions of the parameters of `TSNE`](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). You will probably want to set the `random_state` parameter so that we see what you see.\n",
    "\n",
    "You can change `tsne_params` in one of a couple ways:\n",
    "\n",
    "    tsne_params['parameter1'] = new_value1\n",
    "    tsne_params['parameter2'] = new_value2\n",
    "    tsne_params.update(parameter1=new_value1, parameter2=new_value2)\n",
    "\n",
    "The latter is useful for updating several at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "025d7434c3938d39e28ec5ae719c835a",
     "grade": false,
     "grade_id": "tsne-ans-1",
     "locked": false,
     "points": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# You can also change random_state; the above is just an initial value.\n",
    "# The seed will also affect the outcome of the process.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "95d2f1c2f3441892cd7571b5f0811db1",
     "grade": true,
     "grade_id": "tsne-test",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(**tsne_params)\n",
    "T = tsne.fit_transform(X_iris)\n",
    "df_iris['T0'] = T[:,0]\n",
    "df_iris['T1'] = T[:,1]\n",
    "plot_clusters2d(df_iris, hue='real_labels', vars=['T0','T1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "54aabc893fc5b1a60c6a0928d3c4170a",
     "grade": false,
     "grade_id": "tsne-desc3",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Part 2:\n",
    "What parameters were critical in generating a good visualization? Why do these parameters work compared to the ones before?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e6bcdafc6cdd1e84f2110feb85b525e4",
     "grade": true,
     "grade_id": "tsne-ans-2",
     "locked": false,
     "points": 2,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "80730a05eda8eb8194f92a79cad82d19",
     "grade": false,
     "grade_id": "visblobs-desc-1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Problem 4 (more dimensions, more clusters)\n",
    "\n",
    "Now we're going to generate some random blobs to use in the clustering part of the assignment. We'll generate the blobs, put them in a `DataFrame`, and plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "4929a3071b917e084bd9cd3a96e4b1a7",
     "grade": false,
     "grade_id": "visblobs-code-1",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "n_features = 5\n",
    "n_clusters = 8\n",
    "X_blobs, y_blobs = make_blobs(random_state=201610276, n_features=n_features, centers=n_clusters, n_samples=1000)\n",
    "df_blobs = pd.DataFrame(X_blobs, columns=['B{:d}'.format(i) for i in range(n_features)])\n",
    "df_blobs['blob_labels'] = y_blobs\n",
    "plot_clusters(df_blobs, hue='blob_labels', vars=['B0','B1','B2','B3','B4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d5c6db87c5141023533bd5069c0029e1",
     "grade": false,
     "grade_id": "visblobs-desc-2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Let's go ahead and try PCA. PCA isn't going to help us much (at least for visualization) because the data is just too intrinsically high-dimensional, and it's also too \"spherical\" of a dataset -- that is, there's no \"dominant\" directions like in the Iris dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b9ff9cd3d3b3c4559fafeb14f901f729",
     "grade": false,
     "grade_id": "visblobs-code-2",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "U = PCA(n_components=2).fit_transform(X_blobs)\n",
    "df_blobs['U0'] = U[:,0]\n",
    "df_blobs['U1'] = U[:,1]\n",
    "plot_clusters2d(df_blobs, hue='blob_labels', vars=['U0','U1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6e268d0ec407b4f6cffe0d1c6ea3dfe3",
     "grade": false,
     "grade_id": "visblobs-desc-3",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "PCA many times fails as a visualization tool simply because it's only a linear projection. If there are more than two intrinsic dimensions in the data, then PCA won't display them in the most significant components.\n",
    "\n",
    "### Part 1:\n",
    "Let's try with MDS first. Again, play with the value of `metric`, to see if it gives you a visualization that you like (each run will take a bit of time, since we have more points than the last set of problems):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "fbfcb1b5b42cc11fd39b0a314188ec7e",
     "grade": false,
     "grade_id": "visblobs-ans-1",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6de7d7b974ab14632175d833dff0cec9",
     "grade": true,
     "grade_id": "visblobs-test-1",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "mds = MDS(random_state=201610272, n_init=4, dissimilarity='precomputed')\n",
    "M = mds.fit_transform(other_metrics(X_blobs, metric=metric))\n",
    "df_blobs['M0'] = M[:,0]\n",
    "df_blobs['M1'] = M[:,1]\n",
    "plot_clusters2d(df_blobs, hue='blob_labels', vars=['M0','M1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c105e1d6a3314914d87e7824a8154b08",
     "grade": false,
     "grade_id": "visblobs-desc-4",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Part 2:\n",
    "Let's now try t-SNE, with the parameters you used above. If this gives you a good visualization, just change the code in the following cell to `pass`. If not, update the parameters like above until you get a good visualization. \n",
    "\n",
    "Once you get a good visualization of this data, we'll use it for the problems below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "adcef7c1c2b819fc0ad1af9435b03635",
     "grade": false,
     "grade_id": "visblobs-ans-2",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "db797303ac25180505c035a1b047c442",
     "grade": true,
     "grade_id": "visblobs-test-2",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "T = TSNE(**tsne_params).fit_transform(X_blobs)\n",
    "df_blobs['T0'] = T[:,0]\n",
    "df_blobs['T1'] = T[:,1]\n",
    "plot_clusters2d(df_blobs, hue='blob_labels', vars=['T0','T1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d9c381f470614db3dfbc07257bd8097e",
     "grade": false,
     "grade_id": "sec-2-desc-1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Section 2: $k$-Means and EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6930299e4e1c892364a42ed73ddf35af",
     "grade": false,
     "grade_id": "kmeans-desc-1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Problem 5 ($k$-Means)\n",
    "\n",
    "We would expect $k$-means to do a good job at clustering our blobs dataset. All the blobs are well-separated from one another, and they're roughly circular. We'll use both our MDS and our t-SNE features to visualize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "c78a2002b39f24c2ad31135ded3a54bc",
     "grade": false,
     "grade_id": "kmeans-code-1",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df_blobs['kmeans_labels'] = KMeans(random_state=201610273, n_clusters=n_clusters).fit_predict(X_blobs)\n",
    "plot_clusters2d(df_blobs, hue='kmeans_labels', vars=['M0','M1'])\n",
    "plot_clusters2d(df_blobs, hue='kmeans_labels', vars=['T0','T1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0079268e6ae5b92ae0e01f6ffb373da5",
     "grade": false,
     "grade_id": "kmeans-desc-2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This is pretty much like we expected. Now let's mess with it a bit. \n",
    "\n",
    "We're going to generate a random, symmetric, positive-definite matrix $P$. Most of the time, $P$ will be a nice matrix that stretches inputs by some positive amount in random, orthogonal directions (that is, without any skew). In three dimensions the effect is similar to taking a perfect ball of putty and either squashing it or stretching it.\n",
    "\n",
    "We'll still use our visualization embeddings from before, since we have only affected the data with a linear transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "P = make_spd_matrix(n_dim=n_features, random_state=201610275)\n",
    "X_blobs_stretch = X_blobs.dot(P)\n",
    "\n",
    "df_blobs['kmeans_labels'] = KMeans(random_state=201610273, n_clusters=n_clusters).fit_predict(X_blobs_stretch)\n",
    "plot_clusters2d(df_blobs, hue='kmeans_labels', vars=['M0','M1'])\n",
    "plot_clusters2d(df_blobs, hue='kmeans_labels', vars=['T0','T1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c883ece73b75f4c119338fa6040f122d",
     "grade": false,
     "grade_id": "kmeans-desc-3",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "What has happened to the clusters? Given what you know about $k$-means, why do we see this effect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "720f28e490c38be770bd4c98f5238b81",
     "grade": true,
     "grade_id": "kmeans-ans-1",
     "locked": false,
     "points": 2,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f45344a836262e1764b561152c65569b",
     "grade": false,
     "grade_id": "em-desc-1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Problem 6 (EM)\n",
    "\n",
    "Now let's try with EM. This is implemented in the GMM (Gaussian mixture model) class. Let's use it on the same stretched input and see what happens.\n",
    "\n",
    "(Unfortunately GMM doesn't provide a `fit_predict` shortcut, so we have to do this the long way.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "0de88c56e4dab121fbb5d9288baea14d",
     "grade": false,
     "grade_id": "em-code-1",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df_blobs['gmm_labels'] = GMM(n_components=n_clusters, random_state=201610274).fit(X_blobs_stretch).predict(X_blobs_stretch)\n",
    "plot_clusters2d(df_blobs, hue='gmm_labels', vars=['M0','M1'])\n",
    "plot_clusters2d(df_blobs, hue='gmm_labels', vars=['T0','T1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "078ef155b31987f5b0ecea1159279b73",
     "grade": false,
     "grade_id": "em-desc-2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "1. How is this different from what we saw in $k$-means? \n",
    "2. Why does EM perform better on the squashed data?\n",
    "3. How would you change this example to break EM (if you fiddled with the data above, what did you change)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "8b1a740d5adedac0d0307e972abd1118",
     "grade": true,
     "grade_id": "em-ans-1",
     "locked": false,
     "points": 2,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1111e26e4e4753c6cb38a3697d244a0d",
     "grade": false,
     "grade_id": "part-3-desc-1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Section 3: Spectral Clustering\n",
    "\n",
    "In this section, let's make the problem a little harder. We'll generate the blobs as before, except we're going to force the centers to be just a bit closer together, so it's harder to tease them apart, but there are still obvious blobs that are separate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_blobs_close, y_blobs_close = make_blobs(random_state=201610278, n_features=n_features, centers=n_clusters, n_samples=1000, center_box=(-5,5))\n",
    "df_blobs_close = pd.DataFrame(X_blobs_close, columns=['B{:d}'.format(i) for i in range(n_features)])\n",
    "df_blobs_close['blob_labels'] = y_blobs_close\n",
    "plot_clusters(df_blobs_close, hue='blob_labels', vars=['B0','B1','B2','B3','B4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7257ad2ea37a130f07bfa546e276a110",
     "grade": false,
     "grade_id": "specvis-desc-1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Problem 7 (Spectral Embedding as a Visualization Tool)\n",
    "\n",
    "In order to use spectral clustering, we need a graph. The `SpectralEmbedding` tool builds that graph, computes the Laplacian, and then generates an embedding that we can use for visualization. We'll use $k$-nearest-neighbors, and set up the graph to use the 300 nearest neighbors. We'll also compare the embedding to MDS (using the metric you selected) and t-SNE (using the parameters you settled on):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "91210a586025bf692914a5eb0d226575",
     "grade": false,
     "grade_id": "specvis-code-1",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "spe = SpectralEmbedding(random_state=201610277, n_components=2, n_neighbors=300)\n",
    "S = spe.fit_transform(X_blobs_close)\n",
    "df_blobs_close['S0'] = S[:,0]\n",
    "df_blobs_close['S1'] = S[:,1]\n",
    "plot_clusters2d(df_blobs_close, hue='blob_labels', vars=['S0','S1'])\n",
    "\n",
    "mds = MDS(random_state=201610272, n_init=4, dissimilarity='precomputed')\n",
    "M = mds.fit_transform(other_metrics(X_blobs_close, metric=metric))\n",
    "df_blobs_close['M0'] = M[:,0]\n",
    "df_blobs_close['M1'] = M[:,1]\n",
    "plot_clusters2d(df_blobs_close, hue='blob_labels', vars=['M0','M1'])\n",
    "\n",
    "T = TSNE(**tsne_params).fit_transform(X_blobs_close)\n",
    "df_blobs_close['T0'] = T[:,0]\n",
    "df_blobs_close['T1'] = T[:,1]\n",
    "plot_clusters2d(df_blobs_close, hue='blob_labels', vars=['T0','T1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "de969b5d402de3c8666912b03026fb52",
     "grade": false,
     "grade_id": "specvis-desc-2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "If you found good settings for MDS or t-SNE, you probably notice that the spectral embedding isn't quite as nice. Play with the value of `n_neighbors`, between 125 and 1000 to see if you can improve it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "edf0acd90dd304b289f74b012138fcbf",
     "grade": false,
     "grade_id": "specvis-ans-1",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "n_neighbors = -1\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "150ac780b68c3eb79e587e93c5f98340",
     "grade": true,
     "grade_id": "specvis-test-1",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "spe = SpectralEmbedding(random_state=201610277, n_components=2, n_neighbors=n_neighbors)\n",
    "S = spe.fit_transform(X_blobs_close)\n",
    "df_blobs_close['S0'] = S[:,0]\n",
    "df_blobs_close['S1'] = S[:,1]\n",
    "plot_clusters2d(df_blobs_close, hue='blob_labels', vars=['S0','S1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d4e25c2586dc35be30f574b72b94be25",
     "grade": false,
     "grade_id": "specclust-desc-1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Problem 8 (Spectral Clustering)\n",
    "\n",
    "Now we want to see how well things work if we try to use spectral embeddings to cluster. We don't need to limit ourselves to two components now, since we're clustering. Let's try with thirty to start, and we'll just use $k$-means to cluster the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "034834fcd1cd9c00f4371ce9538879fa",
     "grade": false,
     "grade_id": "specclust-code-1",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "spe_clust = SpectralEmbedding(random_state=201610279, n_components=30, n_neighbors=300)\n",
    "SE = spe_clust.fit_transform(X_blobs_close)\n",
    "spe_km = KMeans(random_state=201610278)\n",
    "df_blobs_close['spe_labels'] = spe_km.fit_predict(SE)\n",
    "plot_clusters2d(df_blobs_close, hue='spe_labels', vars=['S0','S1'])\n",
    "plot_clusters2d(df_blobs_close, hue='spe_labels', vars=['M0','M1'])\n",
    "plot_clusters2d(df_blobs_close, hue='spe_labels', vars=['T0','T1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0d179fef42040ebeb7abe71146f07bf1",
     "grade": false,
     "grade_id": "specclust-desc-2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This is ok, but not great. Play with the value of `n_components` to see if you can improve the clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "e71deac33a583f73cc50fa604dc6bcd4",
     "grade": false,
     "grade_id": "specclust-ans-1",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "n_components = -1\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "57f1618b3eebce6e7b744303f7bdd372",
     "grade": true,
     "grade_id": "specclust-test-1",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "spe_clust = SpectralEmbedding(random_state=201610279, n_components=n_components, n_neighbors=300)\n",
    "SE = spe_clust.fit_transform(X_blobs_close)\n",
    "spe_km = KMeans(random_state=201610278)\n",
    "df_blobs_close['spe_labels'] = spe_km.fit_predict(SE)\n",
    "plot_clusters2d(df_blobs_close, hue='spe_labels', vars=['S0','S1'])\n",
    "plot_clusters2d(df_blobs_close, hue='spe_labels', vars=['M0','M1'])\n",
    "plot_clusters2d(df_blobs_close, hue='spe_labels', vars=['T0','T1'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
