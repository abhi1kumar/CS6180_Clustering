{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8eebc33e238901a106521f669a56dcbf",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# *k*-Medians\n",
    "\n",
    "In this assignment we'll be comparing some different methods of finding *k* medians.\n",
    "\n",
    "First, some boilerplate out of the way:\n",
    "\n",
    "Note that we're using the kcenter.py module from the last assignment, and we have a new module called kmedian.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "fa38527e32416be503923177249efa5e",
     "grade": false,
     "grade_id": "boilerplate",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.metrics import pairwise_distances, pairwise_distances_argmin_min\n",
    "from sklearn.utils.extmath import row_norms\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from kmedian import KMedians\n",
    "from kcenter import KCenters\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Magic function to make matplotlib inline; other style specs must come AFTER\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable high resolution PNGs\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "# Seaborn settings for notebooks\n",
    "rc = {'lines.linewidth': 2, \n",
    "      'axes.labelsize': 18, \n",
    "      'axes.titlesize': 18, \n",
    "      'axes.facecolor': '#DFDFE5'}\n",
    "sns.set(context='notebook', style='darkgrid', rc=rc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b9ba233c65c62d396a0567f26df8fd09",
     "grade": false,
     "grade_id": "plotting-desc",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Plotting\n",
    "\n",
    "We'll be plotting a few things in this assignment, so let's make a function that takes care of this for us. It takes a dataframe, `df`, as well as a list of features `vars` that we care about.\n",
    "\n",
    "The DataFrame `df` should have a column `ypred` that contains integers representing the cluster assignment.\n",
    "\n",
    "This function will do a \"pairplot,\" which makes a set of plots that pairs up every feature listed in `vars`, and produces a 2-d scatterplot. We can add cluster labels as hue, and this function takes care of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "591ca475bbe1b8efe2771b8403d2b54b",
     "grade": false,
     "grade_id": "plotting-fun",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_clusters(df, vars=None): \n",
    "    # Plot the cluster labels:\n",
    "    g = sns.pairplot(data=df, hue='ypred', palette='Dark2', vars=vars)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8b10b3b5bfba54b9cda0c13fc7bde82e",
     "grade": false,
     "grade_id": "dataset-desc",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Dataset \n",
    "\n",
    "Let's load the iris dataset, and massage it for our needs. Almost every dataset needs some kind of treatment like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "cfbd1af62a0cc135902a9762e6e69cfa",
     "grade": false,
     "grade_id": "X-with-dataframe",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# First, load the iris data\n",
    "iris = load_iris()\n",
    "\n",
    "# The data is in list format, so make it into an array:\n",
    "X_iris = np.array(iris.data)\n",
    "iris_samples, iris_features = X_iris.shape\n",
    "\n",
    "# It will be convenient later to randomize the order, \n",
    "# but it's less confusing to do it here\n",
    "order = check_random_state(201609220).permutation(iris_samples)\n",
    "X_iris = X_iris[order]\n",
    "\n",
    "# Give the columns of the DataFrame the names of the features\n",
    "df_iris = pd.DataFrame(X_iris, columns=iris['feature_names'])\n",
    "\n",
    "# Add the actual labels from the dataset into the DataFrame \n",
    "# for comparison\n",
    "df_iris['real_labels'] = np.array(iris['target'])[order]\n",
    "\n",
    "# Finally, the data contains a description of the dataset,\n",
    "# so let's print that out:\n",
    "print iris['DESCR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "43746900aa5838e9e972cf3e80331b9f",
     "grade": false,
     "grade_id": "local-search-desc",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Local search\n",
    "\n",
    "The `kmedian.py` file contains code to perform the local search algorithm. Let's make a quick function that trains a set of cluster centers with local search. This will also save the labels in the DataFrame `df`, and will return the model object, which has properties `medoids_` and `cost_history_` that we'll use.\n",
    "\n",
    "Note: this implementation takes much longer on larger datasets. We've set `verbose` to `True` so that you can see the evolution of the cluster centers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "77eb5fdd221af1afae876ed21b48e407",
     "grade": false,
     "grade_id": "local-search-fun",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def local_search_with(X, df, n_clusters=3, metric='l2'):\n",
    "    \n",
    "    clust = KMedians(n_clusters=n_clusters, metric=metric, tol=1e-5, verbose=True, \n",
    "                      random_state=201609221)\n",
    "    \n",
    "    df['ypred'] = clust.fit_predict(X)\n",
    "    \n",
    "    return clust\n",
    "    \n",
    "ls_model = local_search_with(X_iris, df_iris, metric='l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b02a4e25b98a3df3dbe8906cd2fa264f",
     "grade": false,
     "grade_id": "plot-local-search-desc",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Plot the results of local search\n",
    "Let's plot the clusters, along with cluster centers, and let's also take a look at how the costs have changed over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "8d40ce13ce3edc0db2cf8549801c5c71",
     "grade": false,
     "grade_id": "plot-local-search",
     "locked": true,
     "solution": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_clusters(df_iris, \n",
    "              vars=['sepal length (cm)', 'sepal width (cm)', \n",
    "                    'petal length (cm)', 'petal width (cm)', \n",
    "                    'real_labels'])\n",
    "plt.plot(ls_model.cost_history_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8611c90711d2aed55b34e0a14c48122f",
     "grade": false,
     "grade_id": "choose-medians-desc",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Problem\n",
    "\n",
    "Let's implement a different algorithm for finding $k$ medians, the *$k$-medoids* algorithm. Unlike local search, this algorithm is very straightforward to implement.\n",
    "\n",
    "First, given the current cluster labels, we're going to choose the correct medians for the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "92bc7472e7713b54723bc1b4da8209c0",
     "grade": false,
     "grade_id": "choose-medians-fun",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def choose_medians(X, labels, n_clusters, metric='euclidean'):\n",
    "    \"\"\"\n",
    "    X: float array, (n_samples, n_features) \n",
    "        The input data\n",
    "    labels: int array, (n_samples,)\n",
    "        Numbers that indicate the cluster that the corresponding row of X belongs to\n",
    "    n_clusters:\n",
    "        The number of unique elements in labels\n",
    "    -----------------------------------------------\n",
    "    returns:\n",
    "    medians: float array, (n_clusters, n_features)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get dimensions of `X`\n",
    "    # This information is contained inside the `X` variable. \n",
    "    # Use it to populate `n_samples` and `n_features`.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Allocate the return variable\n",
    "    medians = np.empty((n_clusters, n_features), dtype=np.float64)\n",
    "    \n",
    "    # For every cluster\n",
    "    for i in range(n_clusters):\n",
    "        # Construct a new array `Xi` that contains the examples with label i\n",
    "        # Note: there might only be one, the cluster center. If this is the \n",
    "        #       case, then make sure that `Xi` has shape (1,n_features) and \n",
    "        #       not shape (n_features,).\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        # Find the best example from `Xi` to use as the median. That is, \n",
    "        # compute the row that has the smallest sum of distances to every \n",
    "        # other row of `Xi`.\n",
    "        # \n",
    "        # To do this, take advantage of the `pairwise_distances` function\n",
    "        # from sklearn.metric (it's been imported already). Note that \n",
    "        # `metric` has been passed to this function, so you can use that to\n",
    "        # pass to the `metric` parameter of pairwise_distances.\n",
    "        # \n",
    "        # Hint: This is much easier if you take advantage numpy array func-\n",
    "        #       tionality.\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        # Put the row that you found in the previous step into the corres-\n",
    "        # ponding row of `medians`:\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    return medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "f92264e12be345c2e49dba6f422e38ef",
     "grade": true,
     "grade_id": "choose-medians-test",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "n_clusters = 9\n",
    "X_test = np.eye(n_clusters)\n",
    "labels = np.arange(n_clusters)\n",
    "\n",
    "medians = choose_medians(X_test, labels, n_clusters, metric='l2')\n",
    "\n",
    "assert(medians.shape == (n_clusters,n_clusters))\n",
    "assert(np.isclose(medians.sum(axis=0), X_test.sum(axis=0)).all())\n",
    "\n",
    "X_test = np.zeros((2000,n_clusters))\n",
    "labels = check_random_state(201609222).randint(n_clusters, size=(X_test.shape[0],))\n",
    "X_test[np.arange(2000),labels] = 1.0\n",
    "\n",
    "medians = choose_medians(X_test, labels, n_clusters, metric='l2')\n",
    "\n",
    "assert(medians.shape == (n_clusters,n_clusters))\n",
    "assert(np.isclose(medians.sum(axis=0), np.ones((n_clusters,))).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e264e1a9a40b7a2829f5167af5498b64",
     "grade": false,
     "grade_id": "k-medoids-desc",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Main algorithm\n",
    "\n",
    "We'll now use the function we just wrote in the $k$-medoids algorithm. We pass in our data, a set of inital centers, a tolerance parameter to tell us when to stop, and a metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "5ea962969cfc5679ff0ba5b93164f4f3",
     "grade": false,
     "grade_id": "k-medoids-fun",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def k_medoids(X, init_centers, tol=1e-4, metric='l2'):\n",
    "    n_clusters, n_features = init_centers.shape\n",
    "    \n",
    "    # Find the right labels for the examples against the initial centers\n",
    "    labels, distances = pairwise_distances_argmin_min(X, init_centers, metric=metric)\n",
    "    # Record the initial cost\n",
    "    cost_history = [distances.sum()]\n",
    "\n",
    "    # Keep going until we don't have a significant change (according to `tol`):\n",
    "    while True:\n",
    "        # Use our function that we just wrote\n",
    "        centers = choose_medians(X, labels, n_clusters, metric=metric)\n",
    "        # Get the new labels and distances\n",
    "        labels, distances = pairwise_distances_argmin_min(X, centers, metric=metric)\n",
    "        # Record the cost\n",
    "        cost_history.append(distances.sum())\n",
    "        # If we didn't improve significantly, stop\n",
    "        if cost_history[-1] >= (1-tol)*cost_history[-2]:\n",
    "            break\n",
    "            \n",
    "    return centers, labels, cost_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a84e27306ee9d881d0c19b2d7e7176c8",
     "grade": false,
     "grade_id": "run-k-medoids-random-desc",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Running $k$-medoids\n",
    "\n",
    "Let's take a look at our new algorithm. The performance of $k$-medoids depends greatly on the initial cluster centers we choose. Let's choose random centers first, the easiest way to select centers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "ec399fdf08d0c5bf99618dc9cbffcad0",
     "grade": false,
     "grade_id": "run-k-medoids-random",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# `X` was shuffled, so just take the first 3 rows as cluster centers\n",
    "init_centers = X_iris[:3,:]\n",
    "\n",
    "# Copy the DataFrame so we don't pollute previous results\n",
    "df2 = df_iris.copy()\n",
    "centers, df2['ypred'], cost_history_1 = k_medoids(X_iris, init_centers, tol=1e-5, metric='l2')\n",
    "\n",
    "plot_clusters(df2, \n",
    "              vars=['sepal length (cm)', 'sepal width (cm)', \n",
    "                    'petal length (cm)', 'petal width (cm)', \n",
    "                    'real_labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "67d38cadeb5cd46e7421de1dea51dba8",
     "grade": false,
     "grade_id": "run-k-medoids-random-prob",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Problem\n",
    "\n",
    "How do the clusters compare to the results from local search? Based on the plot, which would you choose and why? The bottom right hand plot features a histogram that indicates the distribution of cluster labels against the real labels of the dataset. How does this compare to the first plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "31f15ded8f4dd141165c522801516ba2",
     "grade": true,
     "grade_id": "run-k-medoids-random-ans",
     "locked": false,
     "points": 2,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "efef8d005f63432cd290ade3c9712518",
     "grade": false,
     "grade_id": "run-k-medoids-random-comp-desc",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Comparing performance\n",
    "\n",
    "Now let's compare the cost at each iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "79d73b7c1e01c7e1ae40b13a950ef21d",
     "grade": false,
     "grade_id": "run-k-medoids-random-comp",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(ls_model.cost_history_, label='Local Search')\n",
    "plt.plot(cost_history_1, label='k-Medoids, random initial centers')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "aa3c8b273d1b3a11ac5cda96c78eed5a",
     "grade": false,
     "grade_id": "run-k-medoids-random-comp-prob",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Problem\n",
    "\n",
    "How do the algorithms compare now? Would you change your previous answer based on what you see? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a0148fbd9bca430e6320e2265b99baf5",
     "grade": true,
     "grade_id": "run-k-medoids-random-comp-ans",
     "locked": false,
     "points": 2,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f95d2ac64aa07fbb6de40658ba00a4a5",
     "grade": false,
     "grade_id": "run-k-medoids-k-centers-desc",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# $k$-Medoids, with $k$-Centers initial centers\n",
    "\n",
    "Now let's try choosing centers by using the $k$-centers algorithm from the previous assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "312fa2f3091bdafbdac02d0dac4be4bf",
     "grade": false,
     "grade_id": "run-k-medoids-k-centers-fun",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "init_centers = KCenters(n_clusters=3, random_state=201609223).fit(X_iris).cluster_centers_\n",
    "\n",
    "df3 = df_iris.copy()\n",
    "centers, df3['ypred'], cost_history_2 = k_medoids(X_iris, init_centers, tol=1e-5, metric='l2')\n",
    "\n",
    "plot_clusters(df3, \n",
    "              vars=['sepal length (cm)', 'sepal width (cm)', \n",
    "                    'petal length (cm)', 'petal width (cm)', \n",
    "                    'real_labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7e5534bfd20ca851cf8b23c34054a638",
     "grade": false,
     "grade_id": "run-k-medoids-k-centers-prob",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Problem\n",
    "\n",
    "How do the clusters compare to the results from local search and k-medoids with random initial clusters? Again, based on the plot, which would you choose and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c038feb8ff4d52af58b2110140d84aba",
     "grade": true,
     "grade_id": "run-k-medoids-k-centers-ans",
     "locked": false,
     "points": 2,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2f1f7404f6fce972bffd11fa00ecb376",
     "grade": false,
     "grade_id": "run-k-medoids-k-centers-comp-desc",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Compare performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "662f7f2e99afbe4c1cef65055d06547a",
     "grade": false,
     "grade_id": "run-k-medoids-k-centers-comp",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(ls_model.cost_history_, label='Local Search')\n",
    "plt.plot(cost_history_1, label='k-Medoids, random initial centers')\n",
    "plt.plot(cost_history_2, label='k-Medoids, k-Centers initial centers')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7344918498f9d140edfe8a91e92f5ce1",
     "grade": false,
     "grade_id": "run-k-medoids-k-centers-comp-prob",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Problem\n",
    "\n",
    "Again, how do the algorithms compare? Would you change your previous answer based on what you see? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e585350b11f60638c89bdbb1427e64e4",
     "grade": true,
     "grade_id": "run-k-medoids-k-centers-comp-ans",
     "locked": false,
     "points": 2,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
